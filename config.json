{
  "training": {
    "batch_size": 64,
    "num_epochs": 2000,
    "log_every": 500,
    "save_every": 10000,
    "lr": 1e-3
  },
  "model": {
    "output_layer": "layer4",
    "d_input": 906,
    "d_model": 256,
    "d_feedforward": 1024,
    "out_channels": 3,
    "num_layers": 4
  }
}